<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

	<title>NIVeL (CVPR 2024)</title>

	<link rel="stylesheet" href="css/fonts.css" type="text/css" charset="utf-8">
	<link rel="stylesheet" href="css/normalize.css" type="text/css" charset="utf-8">
	<link rel="stylesheet" href="css/main.css" type="text/css" charset="utf-8">
	<link rel="stylesheet" href="css/jht.css" type="text/css" charset="utf-8">
	<link rel="stylesheet" href="static/index.css">

	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-23628422-1']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>
</head>

<body style="max-width: none;">
	<div class="right-column" style="max-width: 50em; margin: auto;; margin-top: 3em">

		<h1><b>NIVeL</b>: Neural Implicit Vector Layers for Text-to-Vector Generation</h1>
        <p class="phototext" style="max-width: 45em;">
	        <a href="https://www.purvigoel.com/">Vikas Thamizharasan</a><sup>1,2</sup>,
	        <a href="https://difanliu.github.io/">Difan Liu</a><sup>2</sup>,
	        <a href="https://techmatt.github.io/">Matthew Fisher</a><sup>2</sup>,
	        <a href="http://nxzhao.com/">Nanxuan Zhao</a><sup>2</sup>,<br>
	        <a href="https://kalo-ai.github.io/">Evangelos Kalogerakis</a><sup>1</sup>,
	        <a href="https://research.adobe.com/person/michal-lukac/">Michal Lukáč</a><sup>2</sup><br>
		</p>
        <div class="is-size-5 publication-authors">
          <span class="author-block"><sup>1</sup>University of Massachusetts Amherst, <sup>2</sup>Adobe
            Research</span>
        </div>
		
		<table style="min-width: 625px; margin: auto; text-align: center;">
		<tbody>
		<tr>
			<td>
				<a href="shape_from_tracing__3DV_2020.pdf"><img class="teaser-image" src="paper.png" width="140px"></a>
			</td>
			<td>
				<a href="shape_from_tracing__3DV_2020_supplemental.pdf"><img class="teaser-image" src="paper.png" width="140px"></a>
			</td>
			<td>
				<a href="shapefromtracing_shortvideo.mp4"><img class="teaser-image" src="supplementalvideo.png" width="300px"></a>
			</td>
		</tr>
		<tr>
			<td>
				Paper<br>
				<a href="shape_from_tracing__3DV_2020.pdf">PDF 48 MB</a> | <a href="https://arxiv.org/pdf/2012.03939.pdf">arXiv</a>
			</td>
			<td>
				Supplementary<br>
				<a href="shape_from_tracing__3DV_2020_supplemental.pdf">PDF 18 MB</a>
			</td>
			<td>
				Short Video<br>
				<a href="shapefromtracing_shortvideo.mp4">MP4 5 MB</a>
			</td>
		</tr>
		</tbody>
		</table>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="./" target="_blank" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false"
                        data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 384 512" data-fa-i2svg="">
                        <path fill="currentColor"
                          d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z">
                        </path>
                      </svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Paper</span>
                  </a>
                </span>


                <!-- </span> -->
                <!-- Colab Link. -->
                <span class="link-block">
                  <a href="./" target="_blank" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false"
                        data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 496 512" data-fa-i2svg="">
                        <path fill="currentColor"
                          d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
                        </path>
                      </svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Code</span>
                  </a>
                </span>

              </div>
            </div>

		<!-- <p>
		<img src="teaser_small.png" class="teaser-image" width="480px">
		</p> -->
		
		<h2>Abstract</h2>
		<p>
            Reconstructing object geometry and material from multiple views typically requires optimization. Differentiable path tracing is an appealing framework as it can reproduce complex appearance effects. However, it is difficult to use due to high computational cost. In this paper, we explore how to use differentiable ray tracing to refine an initial coarse mesh and per-mesh-facet material representation. In simulation, we find that it is possible to reconstruct fine geometric and material detail from low resolution input views, allowing high-quality reconstructions in a few hours despite the expense of path tracing. The reconstructions successfully disambiguate shading, shadow, and global illumination effects such as diffuse interreflection from material properties. We demonstrate the impact of different geometry initializations, including space carving, multi-view stereo, and 3D neural networks. Finally, with input captured using smartphone video and a consumer 360 camera for lighting estimation, we also show how to refine initial reconstructions of real-world objects in unconstrained environments
		</p>

        
		<h2>Presentation Video</h2>
		
		<video class="teaser-image" width="720px" controls poster="posterframe.png">
			<source src="shapefromtracing_longvideo.mp4" type="video/mp4">
		</video>
		
		<p>
		<a href="shapefromtracing_longvideo.mp4">Video – 10 mins (MP4 22 MB)</a>
        </p>

		
		<h2>Files</h2>
		
		<table style="min-width: 625px; margin: auto; text-align: center;">
		<tbody>
		<tr>
			<td>
				<a href="shape_from_tracing__3DV_2020.pdf"><img class="teaser-image" src="paper.png" width="140px"></a>
			</td>
			<td>
				<a href="shape_from_tracing__3DV_2020_supplemental.pdf"><img class="teaser-image" src="paper.png" width="140px"></a>
			</td>
			<td>
				<a href="shapefromtracing_shortvideo.mp4"><img class="teaser-image" src="supplementalvideo.png" width="300px"></a>
			</td>
		</tr>
		<tr>
			<td>
				Paper<br>
				<a href="shape_from_tracing__3DV_2020.pdf">PDF 48 MB</a> | <a href="https://arxiv.org/pdf/2012.03939.pdf">arXiv</a>
			</td>
			<td>
				Supplementary<br>
				<a href="shape_from_tracing__3DV_2020_supplemental.pdf">PDF 18 MB</a>
			</td>
			<td>
				Short Video<br>
				<a href="shapefromtracing_shortvideo.mp4">MP4 5 MB</a>
			</td>
		</tr>
		</tbody>
		</table>
        
        
		<h2>Bibtex</h2>
		<pre style="max-width: 700px; margin: auto;">@inproceedings{Goel2020,<br>    author    = "Purvi Goel and Loudon Cohen and James Guesman and Vikas Thamizharasan</br>                 and James Tompkin and Daniel Ritchie",<br>    title     = "Shape from Tracing: Towards Reconstructing 3D Object Geometry<br>                 and SVBRDF Material from Images via Differentiable Path Tracing",<br>    booktitle = "International Conference on 3D Vision (3DV)",<br>    year      = "2020",<br>}</pre>
        
        <h2>Source Code</h2>

        <p><a href="https://github.com/brownvc/shapefromtracing">Github</a></p>


		<h2>Acknowledgements</h2>
		
		<p>
        We would like to thank the anonymous reviewers for the thoughtful and helpful suggestions. We also thank Prof. Min H. Kim for discussions about object capture and reconstruction, and Tzu-Mao Li for discussions about differentiable path tracing. This research was supported by GPU donations from NVIDIA and computer donations from Valve Corporation.
		</p>
		
		<table style="min-width: 625px; margin: auto; text-align: center;">
			<tbody>
				<tr>
					<td>
						<img src="logos/BrownCSLogo.png" width=150px>
                    </td>
                    <td>
						<img src="logos/stanford-logo.png" width=150px>
					</td>
				</tr>
			</tbody>
		</table>
		
		<!-- Little bit of space -->
		<p></p>
		
		<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-36966695-10', 'auto');
		ga('send', 'pageview');

		</script>
	</div>
</body>
