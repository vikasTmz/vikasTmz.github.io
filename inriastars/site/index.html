<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="None">
  
  <link rel="shortcut icon" href="img/favicon.ico">
  <title>Home - Project Report - Internship</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="css/theme.css" type="text/css" />
  <link rel="stylesheet" href="css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Home";
    var mkdocs_page_input_path = "index.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="js/jquery-2.1.1.min.js" defer></script>
  <script src="js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="." class="icon icon-home"> Project Report - Internship</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1 current">
		
    <a class="current" href=".">Home</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#porject-report-internship">Porject Report - Internship</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#november">November</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="datasets/">Datasets</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="codes/">Codes</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href=".">Project Report - Internship</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".">Docs</a> &raquo;</li>
    
      
    
    <li>Home</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="porject-report-internship">Porject Report - Internship</h1>
<p><a href="datasets/">[Datasets]</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="codes/">[Codes]</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="">[ToDo]</a></p>
<p><Description></p>
<h2 id="november">November</h2>
<h3 id="week-1">Week 1</h3>
<h4 id="two-tracks-for-the-project">Two tracks for the project</h4>
<ol>
<li>Generating Face Depth Images given RGB and IR image:</li>
</ol>
<p>Improving depth estimation of faces by providing both RGB and IR image to the GAN.
[Results]
This could be a Siamese network , with two channels to the generator.
Experiment with different loss function.
Introduce labels (gender, age etc.) to Discriminator in-order to <em>improve</em> results.
Experiment with different IR-patterns.
Evaluating Depth output (from RGB-DEPTH paper)
Test ir2depth, binarized IR images, varied internsity and varied depth
 Use IR-GAN as training weights for Gender_CNN : Train Generator with discriminator using only labels and not depth.
[ WISGâ€™18  [1] [2] ]</p>
<ol>
<li>Face analysis from raw data:</li>
</ol>
<p>Add more layers to the CNN architecture / Transfer learning.
Fab-net [learn more]
Teacher student network.</p>
<p><br></p>
<ul>
<li>
<p>Retrained on binarized IR images</p>
<p><strong><pre>Non-binarized IR input               Training loss</pre></strong></p>
<p><pre><img src="img/old_ir.png" alt="drawing" width="250"/>      <img src="img/old_loss.png" alt="drawing" width="300"/></pre></p>
<p><a href="results/v1/">[Test output results (link)]</a></p>
<p><strong><pre>Binarized IR input               Training loss</pre></strong></p>
<p><pre><img src="img/new_ir.png" alt="drawing" width="250"/>      <img src="img/new_loss.png" alt="drawing" width="400"/></pre></p>
<p><a href="results/v3/">[Test output results (link)]</a></p>
<p><strong><pre>Trained on binarized IR images with varying distance from camera</pre></strong></p>
<p><pre><img src="results/v2/images/100_real_A.png" alt="drawing" width="200"/> <img src="results/v2/images/101_real_A.png" alt="drawing" width="200"/> <img src="results/v2/images/102_real_A.png" alt="drawing" width="200"/></pre></p>
<p><a href="results/v2/">[Test output results (link)]</a></p>
<p><strong><pre>Tested on unseen pose and orientation </pre></strong></p>
<p><pre><img src="img/new_ir_new.png" alt="drawing" width="500"/></pre></p>
</li>
</ul>
<p><br></p>
<ul>
<li>
<p>Evaluation metrics</p>
<p>RANSAC, Manhatan distance, RMSE .. some from active stereo nets?</p>
</li>
</ul>
<p><br></p>
<ul>
<li>
<p><a href="http://delivery.acm.org/10.1145/2610000/2601223/a86-fanello.pdf?ip=138.96.200.116&amp;id=2601223&amp;acc=ACTIVE%20SERVICE&amp;key=7EBF6E77E86B478F%2EC083A567C83E14C8%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1541768143_4cc7e69e959933f30c3480cf0ac37ef3">"Learning to be a Depth Camera for Close-Range Human Capture and Interaction", Microsoft Research</a></p>
<p><pre><img src="img/paper1_1.png" alt="drawing" width="400"/><img src="img/paper1_2.png" alt="drawing" width="300"/></pre></p>
<p><em>We present a machine learning technique for estimating absolute, per-pixel depth using any conventional monocular 2D camera, with minor hardware modifications.  Our approach targets close-range human capture and interaction where dense 3D estimation of hands and faces is desired. We use hybrid classification-regression forests to learn how to map from near infrared intensity images to absolute, metric  depth  in  real-time.   We  demonstrate  a  variety  of  human-computer interaction and capture scenarios. Experiments show an accuracy that outperforms a conventional light fall-off baseline, and is comparable to high-quality consumer depth cameras, but with a dramatically reduced cost, power consumption, and form-factor.</em></p>
</li>
</ul>
<p><br></p>
<ul>
<li>
<p>ActiveStereoNet: End-to-End Seld-supervised Learning for Active Stereo Systems</p>
<ul>
<li>precise depth with subpixel precision of 1/30th of a pixel.</li>
<li>does not suffer from over-smoothing issues</li>
<li>preserves edges</li>
<li>handles occlusions</li>
<li>robust to noise and texture-less patches</li>
<li>invariant to illumination changes.</li>
<li>
<p>IR stereo camera pair is used, pseudorandom pattern projected, captures active illumination and passive light.</p>
</li>
<li>
<p>Avoid matching occluded pixels (causes oversmoothing, edge fattening)</p>
</li>
<li>New reconstruction loss based on LCN (local constrast normalization):<ul>
<li>removes low frequency components from passive IR</li>
<li>re-calibrates the strength of active pattern locally to account for fading of patterns with distance.</li>
</ul>
</li>
<li>Window-based loss aggregation with adaptive weights for each pixel<ul>
<li>increase discriminability and reduce the effect of local minima in the stereo cost function.</li>
</ul>
</li>
<li>
<p>Detect and omit occluded pixels in the images during loss computations.</p>
</li>
<li>
<p>Self-supervised vs supervised passive stereo:
    Read how self-supervised passive work.</p>
</li>
<li>
<p>Build-in stereo algorithms in cameras (Intel D400) uses a handcrafted binary descriptor (CENSUS) in combination with a semi-global matching scheme.
        - suffers from common stereo matching issues (edge fattening, quadratic error, occlusions, holes)</p>
</li>
<li></li>
</ul>
</li>
</ul>
<p><br></p>
<ul>
<li>
<p>Received two datasets</p>
</li>
<li>
<p>LS-Net?</p>
</li>
<li>Fab-net and face metrics from IJB</li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="datasets/" class="btn btn-neutral float-right" title="Datasets">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
        <span style="margin-left: 15px"><a href="datasets/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '.';</script>
    <script src="js/theme.js" defer></script>
      <script src="search/main.js" defer></script>

</body>
</html>

<!--
MkDocs version : 1.0.4
Build Date UTC : 2018-11-09 16:55:06
-->
